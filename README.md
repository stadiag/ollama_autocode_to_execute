# ollama_autocode_to_execute
execution of python script auto generated by ollama model (codellama by default) and interpretation by llama3 for NLP

---

# ollama_autocode_to_execute

### ğŸ‡«ğŸ‡· GÃ©nÃ©ration, exÃ©cution et interprÃ©tation automatique de code via Ollama

### ğŸ‡¬ğŸ‡§ Automatic code generation, execution and interpretation using Ollama

---

## ğŸ·ï¸ Badges GitHub / GitHub Badges

<p align="left">

<!-- DerniÃ¨re mise Ã  jour -->

<img src="https://img.shields.io/github/last-commit/stadiag/ollama_autocode_to_execute" />

<!-- Statut des issues -->

<img src="https://img.shields.io/github/issues/stadiag/ollama_autocode_to_execute" />

<!-- Licence (placeholder) -->

<img src="https://img.shields.io/github/license/stadiag/ollama_autocode_to_execute" />

<!-- Taille du repo -->

<img src="https://img.shields.io/github/repo-size/stadiag/ollama_autocode_to_execute" />

<!-- Langage principal -->

<img src="https://img.shields.io/github/languages/top/stadiag/ollama_autocode_to_execute" />

</p>

---

## ğŸ‡«ğŸ‡· Description

Ce projet automatise un pipeline complet oÃ¹ :

1. **Ollama CodeLlama** gÃ©nÃ¨re un script Python Ã  partir dâ€™un prompt.
2. Le script gÃ©nÃ©rÃ© est **exÃ©cutÃ© automatiquement**.
3. Les rÃ©sultats sont **interprÃ©tÃ©s par Llama 3 (NLP)** pour une synthÃ¨se claire et contextualisÃ©e.

---

## ğŸ‡¬ğŸ‡§ Description

This project automates a full workflow where:

1. **Ollama CodeLlama** generates a Python script from a user prompt.
2. The generated script is **executed automatically**.
3. Its results are **interpreted by Llama 3 (NLP)** to provide clear, contextualized output.

---

## ğŸ—‚ï¸ Structure / Structure

* `start.py`

  * ğŸ‡«ğŸ‡· Script principal orchestrant la gÃ©nÃ©ration, lâ€™exÃ©cution et lâ€™analyse.
  * ğŸ‡¬ğŸ‡§ Main script orchestrating generation, execution, and interpretation.

---

## ğŸ› ï¸ PrÃ©requis / Requirements

### ğŸ‡«ğŸ‡·

* Python 3.x
* Ollama installÃ© avec CodeLlama & Llama 3
* DÃ©pendances Python (selon vos fichiers)

### ğŸ‡¬ğŸ‡§

* Python 3.x
* Ollama with CodeLlama & Llama 3 installed
* Python dependencies (depending on your modules)

---

## ğŸš€ Installation & Utilisation / Installation & Usage

### 1. Cloner le dÃ©pÃ´t / Clone the repo

```bash
git clone https://github.com/stadiag/ollama_autocode_to_execute.git
cd ollama_autocode_to_execute
```

### 2. (Optionnel) Environnement virtuel

(Optional) Virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/macOS
# ou: venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 3. VÃ©rifier Ollama / Make sure Ollama is working

* CodeLlama chargÃ©
* Llama 3 disponible

### 4. ExÃ©cuter le pipeline / Run the pipeline

```bash
python start.py
```

---

## ğŸ” Fonctionnement / How it Works

### ğŸ‡«ğŸ‡·

1. Envoi du prompt â†’ CodeLlama gÃ©nÃ¨re un script Python.
2. ExÃ©cution du script dans un environnement contrÃ´lÃ©.
3. Llama 3 interprÃ¨te la sortie.
4. Retour final affichÃ© ou utilisÃ© dans un autre flux.

### ğŸ‡¬ğŸ‡§

1. Prompt is sent â†’ CodeLlama generates a Python script.
2. Script executed in a controlled environment.
3. Llama 3 interprets the output.
4. Final result displayed or processed.

---

## âš ï¸ SÃ©curitÃ© / Security Warning

### ğŸ‡«ğŸ‡·

* Lâ€™exÃ©cution automatique de code gÃ©nÃ©rÃ© est risquÃ©e.
* Ã€ utiliser dans un environnement isolÃ© (sandbox, conteneur).
* Ne jamais exÃ©cuter sur une machine sensible.

### ğŸ‡¬ğŸ‡§

* Auto-executing generated code is dangerous.
* Use a sandbox or container.
* Never run on a sensitive machine.

---

## ğŸ’¡ Cas dâ€™usage / Use Cases

### ğŸ‡«ğŸ‡·

* Automatisation de tÃ¢ches techniques
* GÃ©nÃ©ration rapide dâ€™outils Python
* Analyse automatisÃ©e de rÃ©sultats

### ğŸ‡¬ğŸ‡§

* Task automation
* Rapid Python tool generation
* Automated analysis workflows

---

## ğŸ¤ Contributions / Contributing

### ğŸ‡«ğŸ‡·

Les contributions sont bienvenues : prompts amÃ©liorÃ©s, sÃ©curitÃ©, nouveaux modules.

### ğŸ‡¬ğŸ‡§

Contributions welcome: better prompts, improved safety, new modules.

---

## ğŸ“„ Licence / License

MIT (opensource, fork it ;) )

---

Si tu veux, je peux aussi :
âœ… ajouter un **diagramme du pipeline** (ASCII ou image),
âœ… ajouter une **section "Exemples de prompts"**,
âœ… crÃ©er une version **en anglais sÃ©parÃ©e** dans `README_EN.md`.
